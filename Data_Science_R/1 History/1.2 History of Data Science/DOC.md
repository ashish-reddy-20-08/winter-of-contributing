## HISTORY OF DATA SCIENCE


The term “Data Science” has emerged only recently to specifically designate a new profession that is expected to make sense of the vast stores of big data. 

However, in simple words, data scientists just try to get insights from massive amounts of data that can help companies make smarter business decisions. We also define Data Science as a methodology by which actionable insights can be inferred from data.

![image](https://user-images.githubusercontent.com/63282184/134684611-944f7bf7-7e08-421a-8e3d-dd48d8d4df77.png)

## **Evolution:**

  - Historically, data was evaluated manually which used to take a lot of time and concluded with errors, but nowadays it is automated, and the number of errors has also reduced. With the growth of technology, the number of people dealing with data has also reduced over time. 

**Data Science has revolutionized several different aspects of our world. Let's take a look then at when and where data science comes from.**

**In 1962**, John Tukey wrote about a shift in the world of statistics, saying, “… as I have watched mathematical statistics evolve, I have had cause to wonder and to doubt…I have come to feel that my central interest is in data analysis…” Tukey is referring to the merging of statistics and computers, at a time when statistical results were presented in hours, rather than the days or weeks it would take if done by hand.

**In 1974**, Peter Naur authored the Concise Survey of Computer Methods, using the term “Data Science,” repeatedly. Naur presented his own convoluted definition of the new concept:

“The science of dealing with data, once they have been established, while the relation of the data to what they represent is delegated to other fields and sciences.”

**In 1977**, The IASC, also known as the International Association for Statistical Computing was formed. The first phrase of their mission statement reads, “It is the mission of the IASC to link traditional statistical methodology, modern computer technology, and the knowledge of domain experts in order to convert data into information and knowledge.”

**In 1977**, Tukey wrote a second paper, titled Exploratory Data Analysis, arguing the importance of using data in selecting “which” hypotheses to test, and that confirmatory data analysis and exploratory data analysis should work hand-in-hand.

**In 1989**, the Knowledge Discovery in Databases, which would mature into the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, organized its first workshop.

**In 1994**, Business Week ran the cover story, Database Marketing, revealing the ominous news companies had started gathering large amounts of personal information, with plans to start strange new marketing campaigns. The flood of data was, at best, confusing to company managers, who were trying to decide what to do with so much disconnected information.

**In 1999**, Jacob Zahavi pointed out the need for new tools to handle the massive amounts of information available to businesses, in Mining Data for Nuggets of Knowledge. He wrote:

“Scalability is a huge issue in data mining… Conventional statistical methods work well with small data sets. Today’s databases, however, can involve millions of rows and scores of columns of data… Another technical challenge is developing models that can do a better job analyzing data, detecting non-linear relationships and interaction between elements… Special data mining tools may have to be developed to address web-site decisions.”

**In 2001**, Software-as-a-Service (SaaS) was created. This was the pre-cursor to using Cloud-based applications.

**In 2001**, William S. Cleveland laid out plans for training Data Scientists to meet the needs of the future. He presented an action plan titled, Data Science: An Action Plan for Expanding the Technical Areas of the field of Statistics. It described how to increase the technical experience and range of data analysts and specified six areas of study for university departments. It promoted developing specific resources for research in each of the six areas. His plan also applies to government and corporate research.

**In 2002**, the International Council for Science: Committee on Data for Science and Technology began publishing the Data Science Journal, a publication focused on issues such as the description of data systems, their publication on the internet, applications and legal issues.

**In 2006**, Hadoop 0.1.0, an open-source, non-relational database, was released. Hadoop was based on Nutch, another open-source database.

**In 2008**, the title, “Data Scientist” became a buzzword, and eventually a part of the language. DJ Patil and Jeff Hammerbacher, of LinkedIn and Facebook, are given credit for initiating its use as a buzzword.

**In 2009**, the term NoSQL was reintroduced (a variation had been used since 1998) by Johan Oskarsson, when he organized a discussion on “open-source, non-relational databases”.

**In 2011**, job listings for Data Scientists increased by 15,000%. There was also an increase in seminars and conferences devoted specifically to Data Science and Big Data. Data Science had proven itself to be a source of profits and had become a part of corporate culture.

**In 2011**, James Dixon, CTO of Pentaho promoted the concept of Data Lakes, rather than Data Warehouses. Dixon stated the difference between a Data Warehouse and a Data Lake is that the Data Warehouse pre-categorizes the data at the point of entry, wasting time and energy, while a Data Lake accepts the information using a non-relational database (NoSQL) and does not categorize the data, but simply stores it.

**In 2013**, IBM shared statistics showing 90% of the data in the world had been created within the last two years.

**In 2015**, using Deep Learning techniques, Google’s speech recognition, Google Voice, experienced a dramatic performance jump of 49 percent.

**In 2015**, Bloomberg’s Jack Clark, wrote that it had been a landmark year for Artificial Intelligence (AI). Within Google, the total of software projects using AI increased from “sporadic usage” to more than 2,700 projects over the year.

## **Transition:**

- When we look into the statistics of the careers chosen by people in the past few years, data science is massively adopted by people even from non-technical backgrounds and is doing wonders.


- Data Science has become an important part of business and academic research. Technically, this includes machine translation, robotics, speech recognition, the digital economy, and search engines. In terms of research areas, Data Science has expanded to include the biological sciences, health care, medical informatics, the humanities, and social sciences. Data Science now influences economics, governments, and business and finance.


## Real-Time scenario:
- In the past ten years, Data Science has quietly grown to include businesses and organizations world-wide. It is now being used by governments, geneticists, engineers, and even astronomers. During its evolution, Data Science’s use of Big Data was not simply a “scaling up” of the data, but included shifting to new systems for processing data and the ways data gets studied and analyzed.

- Data Science is seen as a bright field as it has applications all over, ranging from Automobile Industry, IT sector, Healthcare, Army and Weapons, Power and Energy, Banking, and Finance. 
- Some of the real-time applications are, it helps in detecting whether the mail is spam or ham, money transaction is fraud or not, detecting the simplest and busiest air routes, recommendations in amazon and Netflix. 
- It is chosen in many companies, as it helps in summarizing the efficiency of working of the company.



## **It’s future:**

  - The advantage of Data science is, it helps in decision making with less time. We are in an era where time plays a vital role, we always look for an accurate decision. Hence, Data Science is making our life easy and supportive with accurate and efficient results. So data science isn’t the end, it’s a beginning of a new era.




